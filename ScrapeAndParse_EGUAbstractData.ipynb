{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418ee2cb",
   "metadata": {},
   "source": [
    "## Notebook to collect data from EGU abstracts \n",
    "\n",
    "(Years: 2010 -- 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12495f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "import time\n",
    "\n",
    "import codecs\n",
    "\n",
    "import os\n",
    "\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1cc38",
   "metadata": {},
   "source": [
    "#### Configure local paths and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ! pwd\n",
    "root = root[0]\n",
    "\n",
    "print(\"using root directory:\", root)\n",
    "\n",
    "CHROME_DRIVER_PATH=root+\"/deps/chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSED_EGU_DIR =root+\"/egu_parsed/\"\n",
    "\n",
    "if not os.path.exists(PARSED_EGU_DIR):\n",
    "    os.mkdir(PARSED_EGU_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafa41f",
   "metadata": {},
   "source": [
    "#### Initialize webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument(\"--incognito\")\n",
    "browser = webdriver.Chrome(executable_path=CHROME_DRIVER_PATH, options=option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ff07f",
   "metadata": {},
   "source": [
    "#### Define years of interest for collecting data and url template to search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\n",
    "   \"2010\",\n",
    "   \"2011\",\n",
    "   \"2012\",\n",
    "   \"2013\",\n",
    "   \"2014\",\n",
    "   \"2015\",\n",
    "   \"2016\",\n",
    "   \"2017\",\n",
    "   \"2018\",\n",
    "   \"2019\",\n",
    "   \"2020\"    \n",
    "]\n",
    "\n",
    "\n",
    "#egu_template = \"https://ui.adsabs.harvard.edu/search/filter_bibstem_facet_fq_bibstem_facet=AND&filter_bibstem_facet_fq_bibstem_facet=bibstem_facet%3A%22EGUGA%22&fq=%7B!type%3Daqp%20v%3D%24fq_bibstem_facet%7D&fq_bibstem_facet=(bibstem_facet%3A%22EGUGA%22)&q=%20abs%3A(seism%20OR%20earthquake)%20%20year%3A{year}&sort=date%20desc%2C%20bibcode%20desc&p_={page}\"\n",
    "egu_template = \"https://ui.adsabs.harvard.edu/search/q=%20abs%3A(seism%20OR%20earthquake)%20year%3A{year}%20bibstem%3AGeoJI&sort=date%20desc%2C%20bibcode%20desc&p_={page}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f4c7b",
   "metadata": {},
   "source": [
    "#### Define useful functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data structures:\n",
    "\n",
    "def is_initialed_name(name):\n",
    "    first_term = name.split(\" \")[0]\n",
    "    if len(first_term) == 0:\n",
    "        return False\n",
    "    return first_term[-1] == \".\" and first_term[:-1].isupper()\n",
    "\n",
    "print(\"test is_initialed_name- True:\", is_initialed_name(\"J. Smith\"), \", False:\", is_initialed_name(\"Joe Smith\"))\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    # clean the author names\n",
    "    # - remove non-ascii whitespace\n",
    "    # - strip bookend whitespace\n",
    "    # - strip periods from first names if not an initialed name\n",
    "        \n",
    "    name = name.strip()\n",
    "    name = re.sub(r'\\s', ' ', name)\n",
    "    if not is_initialed_name(name):\n",
    "        terms = name.split(\" \")\n",
    "        terms[0] = terms[0].strip(\".\")\n",
    "        name = \" \".join(terms)\n",
    "    return name.strip('.')\n",
    "\n",
    "print(\"test clean name- Colin. J. Cats:\", clean_name(\"Colin. J. Cats\"), \"W. B. Easy:\", clean_name(\"W. B. Easy\"))\n",
    "\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, first_author, all_names, year, month, title, journal):\n",
    "        \n",
    "        self.first_author = clean_name(first_author)\n",
    "        self.names = [clean_name(name) for name in all_names]\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.title = title\n",
    "        self.journal = journal\n",
    "        \n",
    "        # create a unique identifier for this article\n",
    "        self.id = \"_\".join([journal, year, month, \"_\".join(title.translate(str.maketrans('', '', string.punctuation)).split(\" \"))])\n",
    "        \n",
    "        # determine if article has initialed names\n",
    "        self.has_initials = is_initialed_name(first_author)\n",
    "    \n",
    "    def to_map(self):\n",
    "        m = {}\n",
    "        m[\"first_author\"] = self.first_author\n",
    "        m[\"all_names\"] = self.names\n",
    "        m[\"year\"] = self.year\n",
    "        m[\"month\"] = self.month\n",
    "        m[\"title\"] = self.title\n",
    "        m[\"journal\"] = self.journal\n",
    "        m[\"id\"] = self.id\n",
    "        m[\"has_initials\"] = self.has_initials\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scraping (collect html pages with abstract info):\n",
    "\n",
    "def fetch_egu_page(browser, url):\n",
    "    browser.get(url)\n",
    "    if browser.current_url != url:\n",
    "        print(\"unexpected page url.\\n current: {} \\n expected: {}\".format(browser.current_url,url))\n",
    "        return \"\", \"\"\n",
    "    time.sleep(2)\n",
    "    # create a fingerprint for this page\n",
    "    titles = []\n",
    "    elements = browser.find_elements_by_class_name(\"s-results-title\")\n",
    "    for e in elements:\n",
    "        titles.append(e.text)\n",
    "    fingerprint = \" \".join(titles)\n",
    "\n",
    "    return browser.page_source, fingerprint\n",
    "\n",
    "url = egu_template.format(year=\"2013\", page=0)\n",
    "html, fingerprint = fetch_egu_page(browser, url)\n",
    "\n",
    "#print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data parsing (collect useful data from scraped html pages):\n",
    "\n",
    "def parse_egu_page(soup, year):\n",
    "    parsed_articles = []\n",
    "    \n",
    "    articles = soup.find_all(\"div\", class_=\"col-sm-12\")\n",
    "\n",
    "    for a in articles:\n",
    "        title = a.find_all(\"h3\", class_=\"s-results-title\")\n",
    "        if title == \"None\":\n",
    "            #print(\"hit NoneType title\")\n",
    "            continue\n",
    "        if len(title) == 0:\n",
    "            #print(\"hit empty title\")\n",
    "            continue\n",
    "        title = title[0]\n",
    "        title = str(title.get_text())\n",
    "\n",
    "        authors = []\n",
    "        author_field = a.find(\"ul\", class_=\"all-authors\")\n",
    "        author_list = author_field.find_all(\"li\", class_=\"article-author\")\n",
    "        for p in author_list:\n",
    "            author = p.get_text().strip(\";\")\n",
    "            name = author.split(\",\")[::-1]\n",
    "            name = \" \".join(name).strip()\n",
    "            authors.append(str(name))\n",
    "   \n",
    "        if len(authors) == 0:\n",
    "            print(\"hit empty authors. title:\", title)\n",
    "            continue\n",
    "\n",
    "        article = Article(\n",
    "                first_author=authors[0],\n",
    "                all_names=authors,\n",
    "                year=year,\n",
    "                month=\"0\",\n",
    "                title=title,\n",
    "                journal=\"GJI\")\n",
    "        parsed_articles.append(article)\n",
    "    return parsed_articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499f968",
   "metadata": {},
   "source": [
    "#### Run scraping and parsing and save all abstract data in PARSED_EGU_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page starts from 0\n",
    "\n",
    "previous_fingerprint = \"\"\n",
    "\n",
    "for year in years:\n",
    "    print(\"scraping year:\", year)\n",
    "    for page in range(151):\n",
    "        print(\"page:\", page)\n",
    "        url = egu_template.format(year=year, page=page)\n",
    "        html, fingerprint = fetch_egu_page(browser, url)\n",
    "\n",
    "        if len(html) == 0:\n",
    "            print(\"nothing to save for\", url)\n",
    "            continue\n",
    "        if fingerprint == previous_fingerprint:\n",
    "            # page already seen, move to the next month\n",
    "            print(\"done on page\", page)\n",
    "            break\n",
    "        if len(fingerprint) == 0:\n",
    "            print(\"no articles found\")\n",
    "            break\n",
    "        \n",
    "        previous_fingerprint = fingerprint\n",
    "        \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        for article in parse_egu_page(soup, year):\n",
    "            outfile_name = article.id[:80]+\".json\"\n",
    "            with codecs.open(PARSED_EGU_DIR+outfile_name, \"w\", \"utf8\") as outfile:\n",
    "                outfile.write(json.dumps(article.to_map()))\n",
    "                \n",
    "        time.sleep(2)        \n",
    "            \n",
    "print(\"Done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSED_EGU_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
